GitHub Copilot

Unit 1 Questions

1. Define Machine Learning (ML).
2. List the applications of Machine Learning.
3. Explain Supervised Machine Learning with an example.
4. Explain Probably Approximately Correct (PAC) learning with an example.
5. Explain Model Selection and Generalization with an example.
6. Explain the Dimensions of Supervised Machine Learning Algorithms with an example.
7. Explain VC dimension with example
8. Why is VC important?
9. What are the challenges of PAC learning?

Unit 2 Questions

1. What is a feature? (2 marks)
2. What is feature extraction? (2 marks)
3. Explain forward feature selection techniques with example. (4 marks)
4. Explain backward feature selection techniques with example. (4 marks)
5. Explain the following preprocessing steps of data: (4 marks)
6. Explain PCA with core concepts and kernel PCA
7. Simplify the given PCA with examples and eigen values and eigen vectors
8. Explain LDA with example
9. Explain various feature selection techniques (any two)
10. Explain any four forward feature selection techniques.
11. Explain any four backward feature selection techniques.

Unit 3 Questions

1. What is regression?
2. What is linear regression?
3. What is logistic regression?
4. What are the various types of linear regression? (Explain any two in detail)
5. Explain any two linear regression models with examples (lasso and polynomial).
6. Explain logistic regression with any two types
7. What is the stochastic process?
8. What is the stochastic gradient descent algorithm with numerical example
9. Explain the following example stepwise using gradient descent algorithm
10. What is grid search
11. Explain grid search with search
12. What is an exhaustive search
13. What is optimum select with respect to grid search
14. What are the core principles of grid search
15. Compare grid search with random search
16. When should you use grid search?

Unit 4 Questions

1. What is Bayes theorem?
2. Explain naive bayes theorem with example.
3. Solve numerical regarding naive bayes theorem.
4. Explain Bernoulli naive bayes theorem.
5. Explain multinomial naive bayes theorem with example.
6. What is SVM ? / Define SVM
7. Explain SVM and its core concepts.
8. What is the difference between linear SVC and SVC (kernel = "linear")
9. What is the role of kernel trick in SVM ?
10. State advantages and limitations of gaussian naive bayes (Also write applications).
11. Explain the difference between linear SVM and kernel SVM.
12. Apply Bernoulli NV and show prediction steps.

Unit 5 Questions

1. Define entropy / impurity .
2. Differentiate between bagging and boosting.
3. What is the role of voting classifier in ensemble learning ?
4. What does the parameter 'k' represent ?
5. Differentiate between random forest and gradient boosting.
6. Explain impurity measures ( Gini index ) .
7. Explain random forest as an ensemble method & how does it reduce overfitting .
